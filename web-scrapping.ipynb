{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping for Famous TV Shows on themoviedb.org Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](https://camo.githubusercontent.com/951ab659ae6cff9e6560c00155feaf3a225aaf83f76111a068ff61b30cc6e02c/68747470733a2f2f63646e2e6c796e64612e636f6d2f636f757273652f323834383333312f323834383333312d313630373639383038373633392d313678392e6a7067)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Project\n",
    "**WEB SCRAPING** is process for extracting useful data from a website. This information is collected and then exported into a format that is more useful like CVS file or spreadsheet. web scraping can be done manually, in most cases but it is not a simple task most of the times. Websites come in many shapes and forms, as a result, web scrapers vary in functionality and features. Data scraping tools or software can collect and import the data into a program to integrate it with your business workflow.\n",
    "\n",
    "\n",
    "**Python** offers a variety of libraries to scrape and extract the information from the web such as *BeautifulSoup, Requests, Scrapy, Selenium*. Python enables smooth and automatic data scraping for different stages. This process includes interacting with the target destination to parse, extend, import, append and harvest data. Python allows you to automate the scripting, passing, and storage of data in one system.\n",
    "\n",
    "\n",
    "In this **Project** we will scrap TMDB website: https://www.themoviedb.org/tv  and extract a list of popular TV shows and some related information about TV shows.\n",
    "> It involves following main steps.\n",
    "\n",
    "* Making an HTTP request to a server and loading the web page https://www.themoviedb.org/tv using request Library \n",
    "* Inspecting the HTML code of page \n",
    "* Identifying the data we want to extract \n",
    "* parsing the website’s code using BeautifulSoup library\n",
    "* Extracting the list of shows from the main page. For each page, we'll get the\\\n",
    "    **show name, user rating, Show's URL and release date**    \n",
    "* And finally transefering the extracted data into a CSV file using pandas library.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/tLtNldX.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Run Code\n",
    "\n",
    "You can execute the code by clicking the \"Run\" button or by selecting the \"Run on Binder\" option. \n",
    "\n",
    "## Installing required Libraries\n",
    "Let’s start by installing the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the libraries\n",
    "!pip install beautifulsoup4 --upgrade --quiet\n",
    "\n",
    "!pip install requests --upgrade --quiet\n",
    "\n",
    "!pip install pandas --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing required packages\n",
    "Let’s start by installing the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import necessary packages \n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Making an HTTP request and Extracting information from HTML\n",
    "\n",
    "When we access URL https://www.themoviedb.org/tv  using a web browser, it downloads the contents of the web page the URL points to and displays the output on the screen. To extract information from the HTML source code of a webpage programmatically, we can use BeautifulSoup class from the bs4 module of the Beautiful Soup library.\\\n",
    "\n",
    "Steps involves in this process are\n",
    "\n",
    "* Downloading the page using requests.get\n",
    "* Getting response object with the page contents and using a status code check whether the request was successful\n",
    "* Getting the contents of the web page which can be accessed using the .text property of the response.\n",
    "* Creating a HTML file and saving the contents in that file.\n",
    "* create a BeautifulSoup object to parse the content\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definig a  function to download a web page using `requests`\n",
    "tvShow_url = 'https://www.themoviedb.org/tv'\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.48'}\n",
    "def get_show_page(tvShow_url):\n",
    "   # Access the webpage using `requests`\n",
    "    response = requests.get(tvShow_url,headers=headers)\n",
    "    # Check if the request was successful\n",
    "    if response.status_code !=200:\n",
    "        raise Exception('Failed to load page {}'.format(tvShow_url))\n",
    "   #get the page contents\n",
    "    page_contents = response.text\n",
    "     #creating a html file and writing the page contents in that file   \n",
    "    with open('famous-tv-shows.html', 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(response.text)\n",
    "     # Parse the `response' text using BeautifulSoup this will give us a beautifulsoup object\n",
    "    tv_doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "\n",
    "    return tv_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=get_show_page(tvShow_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Inspect\" a website’s source code to extract information\n",
    "\n",
    "Every browser offers a version of the Web Inspector in its Develop tab or simply right click in page and click inspect in chrome.\\\n",
    "With this, we’ll be able to find any hyperlinks and the source of any other materials embedded on the web page. We’ll also be able to read alt text — used to describe the function or content of an image or element on a page — and captions of images, which could include the information we are looking for.\\\n",
    "As we see in the image below, the Tv Shows names are embedded in the a tags under h2 tags.\\\n",
    "![](https://i.imgur.com/GadZKHN.jpg)\n",
    "\n",
    "### Getting Show Names\n",
    "The show's title  are embedded as part of the h2 tag under the text/title attribute.\n",
    "We can use the h2.a.text to retrieve the name of the tvShows.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_names(tv_doc):\n",
    "\n",
    "    \" This Function takes BeautifulSoup object and extracts the show's names from HTML source code.\"\n",
    "    show_names_tags = tv_doc.find_all('h2')[4:]  #Excluding initial h2 tags that dont contain shows' names\n",
    "    show_names = []\n",
    "    # get list of all the show names from the page \n",
    "    for tag in show_names_tags:\n",
    "        show_names.append(tag.a.text.strip())\n",
    "    return show_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El Kebeer Awi',\n",
       " 'My Heart Relieved',\n",
       " 'منهو ولدنا؟',\n",
       " 'Melur Untuk Firdaus',\n",
       " 'Aashiqana',\n",
       " 'The Path',\n",
       " 'Amor Perfeito',\n",
       " 'London Class',\n",
       " 'Till Death',\n",
       " 'Ramadan Kareem',\n",
       " 'Gaafar El Omda',\n",
       " 'Teri Meri Doriyaann',\n",
       " 'Al Maddah',\n",
       " 'Al rojo vivo',\n",
       " 'His All-Knowing Secret',\n",
       " 'Al Aghar',\n",
       " 'Baba Almgal',\n",
       " 'Settohom',\n",
       " 'gold house',\n",
       " \"Al Zind: Thi'b Al Assi\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= get_show_names(doc)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Show's URL\n",
    "The show's URLs  are embedded as part of the h2 tag under the href attribute.\n",
    "We can use the h2.a.href to retrieve the sub url of the tvShows and getting full URL by simply concating base url with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_urls(tv_doc):\n",
    "    \" This Function takes BeautifulSoup object and extracts the show's URLs from HTML source code.\"\n",
    "    show_urls = []\n",
    "    base_url = 'https://www.themoviedb.org'\n",
    "    show_names_tags = tv_doc.find_all('h2')[4:]   #Excluding initial h2 tags that dont contain show's URLs\n",
    "     # get list of all the show URLs from the page \n",
    "    for tag in show_names_tags:\n",
    "        show_urls.append(base_url + tag.a['href'])\n",
    "    return show_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.themoviedb.org/tv/52698',\n",
       " 'https://www.themoviedb.org/tv/101604',\n",
       " 'https://www.themoviedb.org/tv/196080',\n",
       " 'https://www.themoviedb.org/tv/203057',\n",
       " 'https://www.themoviedb.org/tv/203504',\n",
       " 'https://www.themoviedb.org/tv/204370',\n",
       " 'https://www.themoviedb.org/tv/209085',\n",
       " 'https://www.themoviedb.org/tv/211352',\n",
       " 'https://www.themoviedb.org/tv/121745',\n",
       " 'https://www.themoviedb.org/tv/72205',\n",
       " 'https://www.themoviedb.org/tv/218739',\n",
       " 'https://www.themoviedb.org/tv/215103',\n",
       " 'https://www.themoviedb.org/tv/122543',\n",
       " 'https://www.themoviedb.org/tv/101463',\n",
       " 'https://www.themoviedb.org/tv/218313',\n",
       " 'https://www.themoviedb.org/tv/218886',\n",
       " 'https://www.themoviedb.org/tv/218323',\n",
       " 'https://www.themoviedb.org/tv/218320',\n",
       " 'https://www.themoviedb.org/tv/220962',\n",
       " 'https://www.themoviedb.org/tv/221018']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls=get_show_urls(doc)\n",
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Show's Rating\n",
    "The user ratings are embedded as part of the div tag under the user_score_chart class in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_rating(tv_doc):\n",
    "    \n",
    "    \" This Function takes BeautifulSoup object and extracts the show's rating from HTML source code.\"\n",
    "    show_rating_tags = tv_doc.find_all('div', class_= 'user_score_chart')\n",
    "    show_rating = []\n",
    "    # get the list of ratings of all the shows in the page\n",
    "    for tag in show_rating_tags:\n",
    "        show_rating.append(tag.attrs['data-percent'])\n",
    "    return show_rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['66.0',\n",
       " '58.0',\n",
       " '10',\n",
       " '51.0',\n",
       " '76.0',\n",
       " '54.0',\n",
       " '60',\n",
       " '10',\n",
       " '63.0',\n",
       " '40',\n",
       " '56.0',\n",
       " '49.0',\n",
       " '33.0',\n",
       " '17.0',\n",
       " '55.0',\n",
       " '100',\n",
       " '55.0',\n",
       " '10',\n",
       " '100',\n",
       " '90']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=get_show_rating(doc)\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Show's Release Date\n",
    "The show's release dates are embedded in p tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_release_dates(tv_doc):\n",
    "    \" This Function takes BeautifulSoup object and extracts the show's names from HTML source code.\"\n",
    "    show_date_tags = tv_doc.find_all('p')[1:21]\n",
    "    show_dates = []\n",
    "    # get list of all the show's release dates from the page \n",
    "    for tag in show_date_tags:\n",
    "        show_dates.append(tag.text.strip())\n",
    "    return show_dates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aug 11, 2010',\n",
       " 'May 17, 2018',\n",
       " 'Apr 02, 2022',\n",
       " 'Jun 06, 2022',\n",
       " 'May 27, 2022',\n",
       " 'Apr 13, 2021',\n",
       " 'May 27, 2017',\n",
       " 'Apr 13, 2021',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 20, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Jan 04, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 23, 2023',\n",
       " 'Mar 23, 2023']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates=get_release_dates(doc)\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting  up all functions and Creating Database\n",
    "let's make it single code where we put all defined functions and making a dictionary and creating a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "tvShow_url = \"https://www.themoviedb.org/tv\"\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.48'}\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#definig a  function to download a web page using `requests`\n",
    "\n",
    "def get_show_page(tvShow_url):\n",
    "   # Access the webpage using `requests`\n",
    "    response = requests.get(tvShow_url, headers=headers)\n",
    "    # Check if the request was successful\n",
    "    if response.status_code !=200:\n",
    "        raise Exception('Failed to load page {}'.format(tvShow_url))\n",
    "   #get the page contents\n",
    "    page_contents = response.text\n",
    "     #creating a html file and writing the page contents in that file   \n",
    "    with open('famous-tv-shows.html', 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(response.text)\n",
    "     # Parse the `response' text using BeautifulSoup this will give us a beautifulsoup object\n",
    "    tv_doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "\n",
    "    return tv_doc\n",
    "\n",
    "# getting shows' names\n",
    "def get_show_names(tv_doc):\n",
    "\n",
    "    \" This Function takes BeautifulSoup object and extracts the show's names from HTML source code.\"\n",
    "    show_names_tags = tv_doc.find_all('h2')[4:]  #Excluding initial h2 tags that dont contain show names\n",
    "    show_names = []\n",
    "    # get list of all the show names from the page \n",
    "    for tag in show_names_tags:\n",
    "        show_names.append(tag.a.text.strip())\n",
    "    return show_names\n",
    "\n",
    "#getting shows' urls\n",
    "def get_show_urls(tv_doc):\n",
    "    \" This Function takes BeautifulSoup object and extracts the show's URLs from HTML source code.\"\n",
    "    show_urls = []\n",
    "    base_url = 'https://www.themoviedb.org'\n",
    "    show_names_tags = tv_doc.find_all('h2')[4:]   #Excluding initial h2 tags that dont contain shows' URLs\n",
    "     # get list of all the show URLs from the page \n",
    "    for tag in show_names_tags:\n",
    "        show_urls.append(base_url + tag.a['href'])\n",
    "    return show_urls\n",
    "\n",
    "# getting shows' ratings\n",
    "def get_show_rating(tv_doc):\n",
    "    \n",
    "    \" This Function takes BeautifulSoup object and extracts the show's rating from HTML source code.\"\n",
    "    show_rating_tags = tv_doc.find_all('div', class_= 'user_score_chart')\n",
    "    show_rating = []\n",
    "    # get the list of ratings of all the shows in the page\n",
    "    for tag in show_rating_tags:\n",
    "        show_rating.append(tag.attrs['data-percent'])\n",
    "    return show_rating\n",
    "\n",
    "#Getting release dates\n",
    "def get_release_dates(tv_doc):\n",
    "    \" This Function takes BeautifulSoup object and extracts the show's names from HTML source code.\"\n",
    "    show_date_tags = tv_doc.find_all('p')[1:21]  #Excluding some \"p\" tags that dont contain shows' release dates\n",
    "    show_dates = []\n",
    "    # get list of all the show's release dates from the page \n",
    "    for tag in show_date_tags:\n",
    "        show_dates.append(tag.text.strip())\n",
    "      \n",
    "    return show_dates\n",
    "\n",
    "def get_show_details(tv_doc):\n",
    "    \n",
    "    \"Function to get the movie informations genre, runtime and creators\"\n",
    "    div1_tags = tv_doc.find('div', class_ = 'facts')\n",
    "    genre = div1_tags.get_text(strip=True, separator=' ')\n",
    "        \n",
    "    div2_tags = tv_doc.find_all('div', class_= 'scroller_wrap should_fade is_fading')\n",
    "    creator = div2_tags[0].text.strip().partition(\"\\n\")[0]\n",
    "    \n",
    "    return  genre, creator\n",
    "\n",
    "def popular_tvShows():\n",
    "    \n",
    "    \"Function to download web page using `requests` and to extract the HTML source code using BeautifulSoup.\"\n",
    "    \n",
    "    # Getting list of popular shows from the TMdb website\n",
    "    page_count = 1 # Initializing the show page count to 1\n",
    "    \n",
    "    # Declaring lists for all the show's elements\n",
    "    names, ratings, release_dates, urls = [],[],[],[]\n",
    "        \n",
    "    while page_count <= 20: # Looping for 20 pages of the TMdb web page\n",
    "        \n",
    "        tvShow_url = \"https://www.themoviedb.org/tv?page=%d\" %(page_count)\n",
    "        \n",
    "        doc= get_show_page(tvShow_url)\n",
    "      \n",
    "                      \n",
    "        # Append each show attribute to respective lists\n",
    "        names += get_show_names(doc)\n",
    "        ratings += get_show_rating(doc)\n",
    "        release_dates += get_release_dates(doc)\n",
    "        urls += get_show_urls(doc) \n",
    "        page_count += 1\n",
    "\n",
    "        # Defining a dictionary to store the show informations\n",
    "    shows_dict = {\n",
    "        'Name': names,\n",
    "        'Rating': ratings,\n",
    "        'Release_date': release_dates,\n",
    "        'URL': urls\n",
    "    }\n",
    "    \n",
    "    database = pd.DataFrame(shows_dict)\n",
    "    database.to_csv('popular_shows.csv', index=None)\n",
    "    \n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Release_date</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teri Meri Doriyaann</td>\n",
       "      <td>70</td>\n",
       "      <td>Jan 04, 2023</td>\n",
       "      <td>https://www.themoviedb.org/tv/215103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Imlie</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Nov 16, 2020</td>\n",
       "      <td>https://www.themoviedb.org/tv/113218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Titlie</td>\n",
       "      <td>80</td>\n",
       "      <td>Jun 06, 2023</td>\n",
       "      <td>https://www.themoviedb.org/tv/228093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aashiqana</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Jun 06, 2022</td>\n",
       "      <td>https://www.themoviedb.org/tv/203504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do Dil Mil Rahe Hai</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Jun 12, 2023</td>\n",
       "      <td>https://www.themoviedb.org/tv/228627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Sense8</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Jun 05, 2015</td>\n",
       "      <td>https://www.themoviedb.org/tv/61664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>The Misfit of Demon King Academy</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Jul 04, 2020</td>\n",
       "      <td>https://www.themoviedb.org/tv/97617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Animal Kingdom</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Jun 14, 2016</td>\n",
       "      <td>https://www.themoviedb.org/tv/66025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>XO, Kitty</td>\n",
       "      <td>82.0</td>\n",
       "      <td>May 18, 2023</td>\n",
       "      <td>https://www.themoviedb.org/tv/195670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>In Treatment</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Jan 28, 2008</td>\n",
       "      <td>https://www.themoviedb.org/tv/14069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name Rating  Release_date  \\\n",
       "0                 Teri Meri Doriyaann     70  Jan 04, 2023   \n",
       "1                               Imlie   73.0  Nov 16, 2020   \n",
       "2                              Titlie     80  Jun 06, 2023   \n",
       "3                           Aashiqana   67.0  Jun 06, 2022   \n",
       "4                 Do Dil Mil Rahe Hai   77.0  Jun 12, 2023   \n",
       "..                                ...    ...           ...   \n",
       "395                            Sense8   78.0  Jun 05, 2015   \n",
       "396  The Misfit of Demon King Academy   85.0  Jul 04, 2020   \n",
       "397                    Animal Kingdom   77.0  Jun 14, 2016   \n",
       "398                         XO, Kitty   82.0  May 18, 2023   \n",
       "399                      In Treatment   78.0  Jan 28, 2008   \n",
       "\n",
       "                                      URL  \n",
       "0    https://www.themoviedb.org/tv/215103  \n",
       "1    https://www.themoviedb.org/tv/113218  \n",
       "2    https://www.themoviedb.org/tv/228093  \n",
       "3    https://www.themoviedb.org/tv/203504  \n",
       "4    https://www.themoviedb.org/tv/228627  \n",
       "..                                    ...  \n",
       "395   https://www.themoviedb.org/tv/61664  \n",
       "396   https://www.themoviedb.org/tv/97617  \n",
       "397   https://www.themoviedb.org/tv/66025  \n",
       "398  https://www.themoviedb.org/tv/195670  \n",
       "399   https://www.themoviedb.org/tv/14069  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=popular_tvShows()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We've followed the following steps in this project:\n",
    "\n",
    "* Downloaded web pages using the requests library\n",
    "* Inspected the HTML source code of a web page\n",
    "* Parsed parts of a website using Beautiful Soup\n",
    "* Created dictionary with list of information\n",
    "* Complied the shows' informations into Pandas lists and Dataframes\n",
    "* Written dataframes information into CSV file\n",
    "\n",
    "### References\n",
    "\n",
    "1. https://www.youtube.com/watch?v=RKsLLG-bzEY\n",
    "2. https://medium.com/geekculture/web-scraping-cheat-sheet-2021-python-for-web-scraping-cad1540ce21c\n",
    "3. https://www.freecodecamp.org/news/web-scraping-python-tutorial-how-to-scrape-data-from-a-website/\n",
    "4. https://realpython.com/beautiful-soup-web-scraper-python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Notebook on Jovian Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"madhumatti-7/web-scraping-project\" on https://jovian.com\u001b[0m\n",
      "[jovian] Uploading additional files...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m[jovian] Error: Ignoring \"popular_shows\" (not found)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Committed successfully! https://jovian.com/madhumatti-7/web-scraping-project\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.com/madhumatti-7/web-scraping-project'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(files = ['popular_shows'],project=\"web-scraping-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"madhumatti-7/web-scraping-project\" on https://jovian.com\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.com/madhumatti-7/web-scraping-project\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.com/madhumatti-7/web-scraping-project'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}